# Base services used by all configurations
x-airflow-common: &airflow-common
  build:
    context: ./airflow
    dockerfile: Dockerfile  # We'll create a lighter Dockerfile
  environment: &airflow-common-env
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
    - DATABASE_URL=postgresql://airflow:airflow@postgres/job_collection
    - PYTHONPATH=/opt/airflow
  volumes:
    - ./dags:/opt/airflow/dags
    - ./data:/opt/airflow/data
    - ./scripts:/opt/airflow/scripts
  depends_on:
    postgres:
      condition: service_healthy
  # Resource constraints
  deploy:
    resources:
      limits:
        cpus: '0.5'
        memory: 512M
      reservations:
        memory: 256M

networks:
  job_network:
    driver: bridge

services:
  # Database service
  postgres:
    image: postgres:13-alpine  # Use Alpine for smaller footprint
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
      - POSTGRES_MULTIPLE_DATABASES=job_collection
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./postgres-init-script.sh:/docker-entrypoint-initdb.d/postgres-init-script.sh
    networks:
      - job_network
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.7'
          memory: 512M
        reservations:
          memory: 256M

  # Airflow initialization
  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command: >
      -c "airflow db init && airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin && python /opt/airflow/dags/job_utils/db/init_db.py"
    restart: "no"
    networks:
      - job_network
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 384M

  # Airflow webserver
  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    networks:
      - job_network
    profiles:
      - full
      - minimal
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5

  # Airflow scheduler
  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    networks:
      - job_network
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    profiles:
      - full
      - minimal
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 1G
  
  adminer:
    image: adminer:latest
    restart: always
    depends_on:
      - postgres
    networks:
      - job_network
    ports:
      - "8081:8080"
    environment:
      - ADMINER_DEFAULT_SERVER=postgres
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 300M

  # db-dashboard:
  #   <<: *airflow-common
  #   command: python /opt/airflow/scripts/db_dashboard.py
  #   networks:
  #     - job_network
  #   ports:
  #     - "4000:4000"
  #   profiles:
  #     - minimal

# Define a separate profile for data processing services
# These can be enabled with docker-compose --profile data-processing up
  # Spark Master - for NLP processing
  spark-master:
    image: bitnami/spark:3.4.1-debian-11-slim
    environment:
      - SPARK_MODE=master
    ports:
      - "8082:8080"
      - "7077:7077"
    volumes:
      - ./data:/opt/bitnami/spark/data
    profiles:
      - data-processing
    deploy:
      resources:
        limits:
          cpus: '0.8'
          memory: 1G

  # Spark Worker
  spark-worker:
    image: bitnami/spark:3.4.1-debian-11-slim
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G  # Reduced from 2G
      - SPARK_WORKER_CORES=1    # Reduced from default
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/bitnami/spark/data
    profiles:
      - data-processing
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1.2G
        reservations:
          memory: 512M

# Only start these services when actively working with message queues
# docker-compose --profile messaging up
  zookeeper:
    image: bitnami/zookeeper:latest
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    volumes:
      - zookeeper_data:/bitnami/zookeeper
    profiles:
      - messaging
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 256M

  kafka:
    image: bitnami/kafka:latest
    depends_on:
      - zookeeper
    environment:
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_HEAP_OPTS=-Xmx256m -Xms128m  # Reduced heap size
    ports:
      - "9092:9092"
    volumes:
      - kafka_data:/bitnami/kafka
    profiles:
      - messaging
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          memory: 256M

# Use named volumes for better performance and management
volumes:
  pg_data:
  kafka_data:
  zookeeper_data: